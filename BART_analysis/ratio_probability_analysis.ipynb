{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines, get_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/bart.large.xsum',\n",
    "                                           checkpoint_file='model.pt',\n",
    "                                           data_name_or_path='/home/ml/cadencao/Downloads/BART_models/bart.large.xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- fine-tuned bart model loaded.\n"
     ]
    }
   ],
   "source": [
    "finetuned_bart.cuda()\n",
    "finetuned_bart.eval()\n",
    "finetuned_bart.half()\n",
    "print('- fine-tuned bart model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/bart.large',\n",
    "                                 checkpoint_file='model.pt',\n",
    "                                 data_name_or_path='/home/ml/cadencao/Downloads/BART_models/bart.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- bart model loaded.\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "bart.half()\n",
    "print('- bart model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = bart.encode\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_encoder = finetuned_bart.model.encoder\n",
    "bart_decoder = finetuned_bart.model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fairseq.models.transformer.TransformerEncoder'>\n",
      "<class 'fairseq.models.transformer.TransformerDecoder'>\n"
     ]
    }
   ],
   "source": [
    "print(type(bart_encoder))\n",
    "print(type(bart_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301\n"
     ]
    }
   ],
   "source": [
    "document_path = '/home/ml/cadencao/XSum/fairseq_files/test.source'\n",
    "target_path = '/home/ml/cadencao/XSum/fairseq_files/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(src_input, verbose=False):\n",
    "    src_inputs = [src_input]  # list of input string\n",
    "    src_tokens = collate_tokens([encode_func(i) for i in src_inputs], pad_idx=1, left_pad=True)\n",
    "    src_tokens = src_tokens.cuda()\n",
    "    src_lengths = torch.sum(src_tokens != 1, dim=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print('- src tokens: {};\\n- src lengths: {}'.format(src_tokens.shape, src_lengths.shape))\n",
    "    return src_tokens, src_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(decoder, encoder_out, tgt_tokens=None, min_decode_step=10, max_decode_step=60, pad_id=1, eos_id=2, verbose=True):\n",
    "    init_input = torch.tensor([[2, 0]] * src_tokens.shape[0], dtype=torch.long).cuda()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    token_probs, tokens = [], []\n",
    "\n",
    "    for step in range(max_decode_step):\n",
    "        decoder_outputs = decoder(init_input, encoder_out, features_only=False)\n",
    "        logits = decoder_outputs[0][:, -1, :]  # [batch_size, vocab]\n",
    "        \n",
    "        if step + 1 < min_decode_step:\n",
    "            logits[:, eos_id] = -math.inf\n",
    "        logits[:, pad_id], logits[:, 0] = -math.inf, -math.inf  # never select pad, start token\n",
    "\n",
    "        probs = softmax(logits)\n",
    "        assert logits.shape == probs.shape\n",
    "        attn = decoder_outputs[1]['attn'][0]  # [batch_size, prev_token_len, src_token_len]\n",
    "        assert logits.dim() == 2 and attn.dim() == 3\n",
    "\n",
    "        if tgt_tokens is not None:\n",
    "            selected_token = tgt_tokens[step].unsqueeze(0)\n",
    "        else:\n",
    "            value, indices = torch.topk(probs, 5, dim=1)\n",
    "            selected_token = indices[:, 0]\n",
    "\n",
    "#             if step == 1:\n",
    "#                 selected_token = indices[:, 0]\n",
    "#             elif step == 10:\n",
    "#                 selected_token = indices[:, 0]\n",
    "#             elif step == 12:\n",
    "#                 selected_token = indices[:, 0]\n",
    "\n",
    "        init_input = torch.cat([init_input, selected_token.unsqueeze(1)], dim=-1)\n",
    "        token, prob = decode_func(selected_token), probs.squeeze()[selected_token.item()].item()\n",
    "        token_probs.append(prob)\n",
    "        tokens.append(token)\n",
    "\n",
    "        if selected_token.item() == eos_id:\n",
    "            break\n",
    "        elif verbose:\n",
    "            print(\"- {:02d}: {} ({:.2f})\".format(step, token, prob), end='\\n')\n",
    "\n",
    "    return init_input, tokens, token_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_mask(input_sentence):\n",
    "    bpe_code = bart.bpe.encode(input_sentence)  # <mask>: 1279 27932 29\n",
    "    input_ids = bart.task.source_dictionary.encode_line('<s> ' + bpe_code.replace('1279 27932 29', '<mask>'), \n",
    "                                                        append_eos=True).long()\n",
    "    input_ids = input_ids.unsqueeze(0).cuda()\n",
    "    src_lengths = torch.sum(input_ids != 1, dim=1)\n",
    "    return input_ids, src_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For $235, #### ## ship 6'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'For $235, #### will ship 6'.replace('will', '##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1890 720 22370 11 1303 21017 481 4074 718'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.bpe.encode('For $235, #### will ship 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1890 720 21017 13 339 481 4074 718'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.bpe.encode('For $###. he will ship 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4242 837 339 481 4074 718'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.bpe.encode('#### , he will ship 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4242 11 339 481 4074 718'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.bpe.encode('####, he will ship 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.bpe.decode('1303')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = bart.task.source_dictionary.encode_line('27 27932 29 8276 50026 7372 22559 23780 418 2539 468 4488 257 2775 1279 27932 22330 543 481 766 683 3520 379 10578 6839 10499 1566 262 3931 286 13130 13',\n",
    "                                                    append_eos=True).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<mask> somebody Ulster centre Stuart McCloskey has signed a contract <mask>, which will see him remain at Kingspan Stadium until the summer of 2019.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Conditional Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 23])\n",
      "Ireland and Ulster back Stuart McCloskey has signed a new three-year contract with the province.\n",
      "\n",
      "- entity: Ireland\n",
      "- prior: 2.6226043701171875e-06\n",
      "- posterior: 0.423583984375\n",
      "- ratio: 0.424 / 0.000 = 33557.574\n",
      "\n",
      "- entity: Ulster\n",
      "- prior: 0.1962890625\n",
      "- posterior: 0.88818359375\n",
      "- ratio: 0.888 / 0.196 = 4.525\n",
      "\n",
      "- entity: Stuart McCloskey\n",
      "- prior: 0.00516355092622689\n",
      "- posterior: 0.32229159308417366\n",
      "- ratio: 0.322 / 0.005 = 62.296\n",
      "\n",
      "- entity: three-year\n",
      "- prior: 0.1528004475403577\n",
      "- posterior: 0.17944228858686984\n",
      "- ratio: 0.179 / 0.153 = 1.174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "src_tokens, src_lengths = tokenize(xsum_source[INDEX])\n",
    "\n",
    "# encode & decode\n",
    "encoder_out = finetuned_bart.model.encoder(src_tokens, src_lengths=src_lengths)\n",
    "output_ids, tokens, token_probs = generate_sequence(bart_decoder, encoder_out, verbose=False)\n",
    "\n",
    "print(output_ids.shape)\n",
    "\n",
    "hypothesis = decode_func(output_ids[0])\n",
    "print(hypothesis + '\\n')\n",
    "\n",
    "ent_parts = ' '.join([e.text for e in nlp(hypothesis).ents]).split()\n",
    "ent_parts = [e.text for e in nlp(hypothesis).ents]\n",
    "for entity in ent_parts:\n",
    "    masked_summary = hypothesis.replace(entity, '<mask>')\n",
    "\n",
    "    masked_input, masked_lengths = tokenize_with_mask(masked_summary)\n",
    "    masked_outputs = generate_sequence(bart.model.decoder,\n",
    "                                       bart.model.encoder(masked_input,\n",
    "                                                          src_lengths=masked_lengths),\n",
    "                                       tgt_tokens=output_ids[0][2:],\n",
    "                                       verbose=False)\n",
    "    masked_output_ids, masked_tokens, masked_token_probs = masked_outputs\n",
    "    assert decode_func(masked_output_ids[0]) == hypothesis\n",
    "\n",
    "    posterior = get_probability(entity, tokens, token_probs)\n",
    "    prior = get_probability(entity, masked_tokens, masked_token_probs)\n",
    "    \n",
    "    print('- entity: {}'.format(entity))\n",
    "    print('- prior: {}'.format(prior))\n",
    "    print('- posterior: {}'.format(posterior))\n",
    "    print('- ratio: {:.3f} / {:.3f} = {:.3f}'.format(posterior, prior, posterior / (prior + 1e-5)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ulster centre Stuart McCloskey has signed a contract extension which will see him remain at Kingspan Stadium until the summer of 2019.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_target[INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 271])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([271, 1, 1024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
