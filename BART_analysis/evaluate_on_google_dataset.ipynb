{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disturbed-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-sally",
   "metadata": {},
   "source": [
    "#### Read Google Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "novel-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "factuality_data = json.load(open('../Dataset/xsum_hallucination_annotations/factuality_annotations_xsum_summaries.json'))\n",
    "hallucination_data = json.load(open('../Dataset/xsum_hallucination_annotations/hallucination_annotations_xsum_summaries.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controlled-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5597\n",
      "11185\n"
     ]
    }
   ],
   "source": [
    "print(len(factuality_data))\n",
    "print(len(hallucination_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "friendly-insurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbcid': 29911712,\n",
       " 'system': 'BERTS2S',\n",
       " 'summary': 'more than 50 pupils at a bristol academy have been sent home from school because of a lack of uniform.',\n",
       " 'is_factual': 'no',\n",
       " 'worker_id': 'wid_0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factuality_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "provincial-pillow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbcid': 34687720,\n",
       " 'system': 'BERTS2S',\n",
       " 'summary': 'rory mcilroy will take a one-shot lead into the final round of the wgc-hsbc champions after carding a three-under',\n",
       " 'hallucination_type': 'extrinsic',\n",
       " 'hallucinated_span': 'rory mcilroy will take a one-shot lead into the final round of the wgc-hsbc champions after carding a three-under',\n",
       " 'worker_id': 'wid_0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-welsh",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-climate",
   "metadata": {},
   "source": [
    "#### Read Calculated Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brave-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data_with_proba = json.load(open('google_data_with_proba.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "overall-puppy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(google_data_with_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advance-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'rory mcilroy moved to within a shot of joint leaders victor dubuisson and jaco van zyl after the third round of the turkish airlines open.',\n",
       " 'summary_upper': 'Rory McIlroy moved to within a shot of joint leaders Victor Dubuisson and Jaco van Zyl after the third round of the Turkish Airlines open .',\n",
       " 'ents': [{'start': 0,\n",
       "   'end': 4,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'Rory',\n",
       "   'prior': 0.380859375,\n",
       "   'posterior': 0.93017578125},\n",
       "  {'start': 5,\n",
       "   'end': 12,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'McIlroy',\n",
       "   'prior': 0.9189453125,\n",
       "   'posterior': 0.78173828125},\n",
       "  {'start': 53,\n",
       "   'end': 59,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'Victor',\n",
       "   'prior': 0.0023136138916015625,\n",
       "   'posterior': 0.000522613525390625},\n",
       "  {'start': 60,\n",
       "   'end': 69,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'Dubuisson',\n",
       "   'prior': 0.97119140625,\n",
       "   'posterior': 0.82958984375},\n",
       "  {'start': 74,\n",
       "   'end': 78,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'Jaco',\n",
       "   'prior': 0.048187255859375,\n",
       "   'posterior': 0.0057220458984375},\n",
       "  {'start': 79,\n",
       "   'end': 82,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'van',\n",
       "   'prior': 0.53369140625,\n",
       "   'posterior': 0.46484375},\n",
       "  {'start': 83,\n",
       "   'end': 86,\n",
       "   'label': -1,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'Zyl',\n",
       "   'prior': 0.75,\n",
       "   'posterior': 0.90576171875},\n",
       "  {'start': 97,\n",
       "   'end': 102,\n",
       "   'label': -1,\n",
       "   'type': 'ORDINAL',\n",
       "   'ent': 'third',\n",
       "   'prior': 0.107666015625,\n",
       "   'posterior': 0.1309814453125},\n",
       "  {'start': 116,\n",
       "   'end': 132,\n",
       "   'label': -1,\n",
       "   'type': 'ORG',\n",
       "   'ent': 'Turkish Airlines',\n",
       "   'prior': 0.0064544677734375,\n",
       "   'posterior': 1.5437602996826172e-05}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_data_with_proba['34687720']['Gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-approval",
   "metadata": {},
   "source": [
    "#### Claculate Factuality Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tutorial-roberts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbcid': 29911712,\n",
       " 'system': 'BERTS2S',\n",
       " 'summary': 'more than 50 pupils at a bristol academy have been sent home from school because of a lack of uniform.',\n",
       " 'is_factual': 'no',\n",
       " 'worker_id': 'wid_1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factuality_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "published-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "factuality = {}\n",
    "for i, f in enumerate(factuality_data):\n",
    "    if f['bbcid'] not in factuality:\n",
    "        factuality[f['bbcid']] = {}\n",
    "    if f['system'] not in factuality[f['bbcid']]:\n",
    "        factuality[f['bbcid']][f['system']] = []\n",
    "        \n",
    "    if f['is_factual'] == 'yes':\n",
    "        factuality[f['bbcid']][f['system']].append(True)\n",
    "    elif f['is_factual'] == 'no':\n",
    "        factuality[f['bbcid']][f['system']].append(False)\n",
    "    elif f['is_factual'] is None:\n",
    "        factuality[f['bbcid']][f['system']].append(False)\n",
    "    else:\n",
    "        print(i)\n",
    "        raise Exception('Unkown Label: {}'.format(f['is_factual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination = {}\n",
    "for h in hallucination_data:\n",
    "    if h['bbcid'] not in hallucination:\n",
    "        hallucination[h['bbcid']] = {}\n",
    "    if h['system'] not in hallucination[h['bbcid']]:\n",
    "        hallucination[h['bbcid']][h['system']] = []\n",
    "    \n",
    "    if h['hallucination_type'] == 'extrinsic' and len(h['hallucinated_span']) < len(h['summary']):\n",
    "        hallucination[h['bbcid']][h['system']].append(h['hallucinated_span'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "north-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity in hallucination span (extrinsic), and summary false: false-hallucination\n",
    "# entity in hallucination span (extrinsic), and summary true: true-hallucnination\n",
    "# entity not in hallucination span and summary true: non-hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "turkish-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'rory mcilroy will take a one-shot lead into the final round of the wgc-hsbc champions after carding a three-under',\n",
       " 'summary_upper': 'Rory McIlroy will take a one-shot lead into the final round of the Wgc-Hsbc champions after carding a Three-Under',\n",
       " 'ents': [{'start': 0,\n",
       "   'end': 4,\n",
       "   'label': 2,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'Rory',\n",
       "   'prior': 0.379150390625,\n",
       "   'posterior': 0.923828125},\n",
       "  {'start': 5,\n",
       "   'end': 12,\n",
       "   'label': 2,\n",
       "   'type': 'PERSON',\n",
       "   'ent': 'McIlroy',\n",
       "   'prior': 0.97119140625,\n",
       "   'posterior': 0.7802734375},\n",
       "  {'start': 25,\n",
       "   'end': 28,\n",
       "   'label': 2,\n",
       "   'type': 'CARDINAL',\n",
       "   'ent': 'one',\n",
       "   'prior': 0.004116058349609375,\n",
       "   'posterior': 0.1072998046875},\n",
       "  {'start': 63,\n",
       "   'end': 75,\n",
       "   'label': 2,\n",
       "   'type': 'ORG',\n",
       "   'ent': 'the Wgc-Hsbc',\n",
       "   'prior': 0.0,\n",
       "   'posterior': 0.0},\n",
       "  {'start': 102,\n",
       "   'end': 107,\n",
       "   'label': 2,\n",
       "   'type': 'CARDINAL',\n",
       "   'ent': 'Three',\n",
       "   'prior': 1.138448715209961e-05,\n",
       "   'posterior': 0.00046896934509277344}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_data_with_proba['34687720']['BERTS2S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "statutory-negotiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factuality[34687720]['BERTS2S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "later-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the final round of the wgc-hsbc champions']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination[34687720]['BERTS2S']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-biography",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "focused-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_google_evaluation import read_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hairy-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_factual(scores):\n",
    "    if None in scores: return False\n",
    "#     if len(scores) == sum(scores):\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "    if sum(scores) * 2 >= len(scores):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprising-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hallucinated(entity, spans):\n",
    "    for s in spans:\n",
    "        if entity in s:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thrown-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_label, hallucination_label, posterior_label = [], [], []\n",
    "prior_probs, posterior_probs = [], []\n",
    "overlap_preds, threshold_preds = [], []\n",
    "\n",
    "for bbcid in google_data_with_proba:\n",
    "    for system in google_data_with_proba[bbcid]:\n",
    "        if int(bbcid) not in factuality or system not in factuality[int(bbcid)]: continue\n",
    "    \n",
    "        for e in google_data_with_proba[bbcid][system]['ents']:\n",
    "            if 'posterior' not in e or e['posterior'] is None: continue\n",
    "            \n",
    "            is_factual = check_factual(factuality[int(bbcid)][system])\n",
    "            is_hallucinated = check_hallucinated(e['ent'], hallucination[int(bbcid)][system])\n",
    "\n",
    "            if is_factual and is_hallucinated:\n",
    "                factual_label.append(1)\n",
    "                hallucination_label.append(1)\n",
    "            elif is_factual and not is_hallucinated:\n",
    "                factual_label.append(1)\n",
    "                hallucination_label.append(0)\n",
    "            elif (not is_factual) and is_hallucinated:\n",
    "                factual_label.append(0)\n",
    "                hallucination_label.append(1)\n",
    "            elif (not is_factual) and (not is_hallucinated):\n",
    "                factual_label.append(0)\n",
    "                hallucination_label.append(0)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            prior_probs.append(e['prior'])\n",
    "            posterior_probs.append(e['posterior'])\n",
    "            \n",
    "            if e['posterior'] > e['prior']:\n",
    "                posterior_label.append(1)\n",
    "            else:\n",
    "                posterior_label.append(0)\n",
    "                \n",
    "            if e['ent'].lower() in read_document(int(bbcid)).lower():\n",
    "                overlap_preds.append(1)\n",
    "            else:\n",
    "                overlap_preds.append(0)\n",
    "                \n",
    "            if e['posterior'] > 0.4:\n",
    "                threshold_preds.append(1)\n",
    "            else:\n",
    "                threshold_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "textile-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5508\n"
     ]
    }
   ],
   "source": [
    "print(len(factual_label))\n",
    "assert len(factual_label) == len(posterior_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-prediction",
   "metadata": {},
   "source": [
    "#### Overlap Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "italian-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "moved-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.9426    0.5594    0.7022      5080\n",
      "     Factual     0.1023    0.5958    0.1746       428\n",
      "\n",
      "    accuracy                         0.5623      5508\n",
      "   macro avg     0.5225    0.5776    0.4384      5508\n",
      "weighted avg     0.8773    0.5623    0.6612      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(factual_label, threshold_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surrounded-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.9273    0.3915    0.5506      5080\n",
      "     Factual     0.0809    0.6355    0.1435       428\n",
      "\n",
      "    accuracy                         0.4105      5508\n",
      "   macro avg     0.5041    0.5135    0.3470      5508\n",
      "weighted avg     0.8615    0.4105    0.5190      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(factual_label, overlap_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "answering-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.2159    0.6652    0.3259       696\n",
      "     Factual     0.9307    0.6505    0.7657      4812\n",
      "\n",
      "    accuracy                         0.6523      5508\n",
      "   macro avg     0.5733    0.6578    0.5458      5508\n",
      "weighted avg     0.8404    0.6523    0.7102      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], overlap_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-acrobat",
   "metadata": {},
   "source": [
    "#### LM-based Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ahead-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.9376    0.3638    0.5242      5080\n",
      "     Factual     0.0862    0.7126    0.1538       428\n",
      "\n",
      "    accuracy                         0.3909      5508\n",
      "   macro avg     0.5119    0.5382    0.3390      5508\n",
      "weighted avg     0.8714    0.3909    0.4954      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(factual_label, posterior_label, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "russian-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.1558    0.4411    0.2302       696\n",
      "     Factual     0.8900    0.6542    0.7541      4812\n",
      "\n",
      "    accuracy                         0.6273      5508\n",
      "   macro avg     0.5229    0.5476    0.4922      5508\n",
      "weighted avg     0.7972    0.6273    0.6879      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], posterior_label, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-feeding",
   "metadata": {},
   "source": [
    "#### Load KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "swiss-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "indirect-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "\n",
    "knn_model = pickle.load(open('classifiers/knn_main_factual_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "monthly-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = knn_model.predict(np.array([prior_probs, posterior_probs]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "brave-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.1904    0.4152    0.2611       696\n",
      "     Factual     0.8980    0.7446    0.8141      4812\n",
      "\n",
      "    accuracy                         0.7030      5508\n",
      "   macro avg     0.5442    0.5799    0.5376      5508\n",
      "weighted avg     0.8086    0.7030    0.7442      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], prediction, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "naked-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main model: n = 7\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#  Non-factual     0.1904    0.4152    0.2611       696\n",
    "#      Factual     0.8980    0.7446    0.8141      4812\n",
    "\n",
    "#     accuracy                         0.7030      5508\n",
    "#    macro avg     0.5442    0.5799    0.5376      5508\n",
    "# weighted avg     0.8086    0.7030    0.7442      5508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "indian-colorado",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-factual     0.9407    0.2811    0.4329      5080\n",
      "     Factual     0.0847    0.7897    0.1530       428\n",
      "\n",
      "    accuracy                         0.3206      5508\n",
      "   macro avg     0.5127    0.5354    0.2929      5508\n",
      "weighted avg     0.8742    0.3206    0.4111      5508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(factual_label, prediction, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "personal-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report([1 if i == 0 else 0 for i in hallucination_label], prediction, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nuclear-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#  Non-factual     0.7426    0.5708    0.6454       657\n",
    "#      Factual     0.5138    0.6963    0.5913       428\n",
    "\n",
    "#     accuracy                         0.6203      1085\n",
    "#    macro avg     0.6282    0.6335    0.6184      1085\n",
    "# weighted avg     0.6523    0.6203    0.6241      1085\n",
    "\n",
    "# LM + KNN\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#  Non-factual     0.6784    0.7900    0.7300       657\n",
    "#      Factual     0.5687    0.4252    0.4866       428\n",
    "\n",
    "#     accuracy                         0.6461      1085\n",
    "#    macro avg     0.6236    0.6076    0.6083      1085\n",
    "# weighted avg     0.6352    0.6461    0.6340      1085"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
