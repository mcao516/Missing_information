{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from fairseq.models.bart import BARTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/bart.large',\n",
    "                                 checkpoint_file='model.pt',\n",
    "                                 data_name_or_path='/home/ml/cadencao/Downloads/BART_models/bart.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Activate evaluation mode\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "print('- Activate evaluation mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = bart.encode\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_encoder = bart.model.encoder\n",
    "bart_decoder = bart.model.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = '/home/ml/cadencao/XSum/fairseq_files/train.source'\n",
    "target_path = '/home/ml/cadencao/XSum/fairseq_files/train.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Loss Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 4\n",
    "folder = 'cedar_losses/'\n",
    "\n",
    "files = [f for f in listdir(folder) if isfile(join(folder, f)) and f[:len(str(ID))] == str(ID) and f[len(str(ID))] == '.']\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = None\n",
    "losses = []\n",
    "\n",
    "for f in files:\n",
    "    s = torch.load(join(folder, f), map_location='cpu')\n",
    "    if target is None:\n",
    "        target = s['sample']['target'][0]\n",
    "    else:\n",
    "        assert torch.all(target.eq(s['sample']['target'][0])).item()\n",
    "    token_loss = s['token_loss'].view(s['sample']['target'].shape)[0]\n",
    "    assert token_loss.shape == target.shape\n",
    "    losses.append(token_loss.numpy())\n",
    "\n",
    "losses = np.array(losses).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import tokenize, decode_sequence, get_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decode_func(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(target[:-1]):\n",
    "    # print('{} ({})'.format(decode_func(t.unsqueeze(dim=0)), i), end=' ')\n",
    "    print('- {} {}'.format(i, decode_func(t.unsqueeze(dim=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_index = [0, 1, 2, 3, 18, 20, 21, 24, 25, 26]\n",
    "display_index = [0, 1, 2, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "display_index = None\n",
    "\n",
    "x = np.arange(0, losses.shape[1], 1)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20.0, 10.0))\n",
    "\n",
    "count = 0\n",
    "for i, t in enumerate(target):\n",
    "    if t.item() == 1: break\n",
    "    word = decode_func(t.unsqueeze(dim=0))\n",
    "    if display_index is None or i in display_index:\n",
    "        axs.plot(x, losses[i], label=word)\n",
    "        \n",
    "        text_index = np.argmax(losses[i])\n",
    "        axs.text(text_index, losses[i][text_index] + 0.05, word,\n",
    "                 horizontalalignment='center')\n",
    "        count += 1\n",
    "\n",
    "axs.set_xlabel('Epoch')\n",
    "axs.set_ylabel('Training loss')\n",
    "axs.grid(True)\n",
    "\n",
    "# plt.legend()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('foo.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_target[ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_mask(input_sentence):\n",
    "    bpe_code = bart.bpe.encode(input_sentence)  # <mask>: 1279 27932 29\n",
    "    input_ids = bart.task.source_dictionary.encode_line('<s> ' + bpe_code.replace('1279 27932 29', '<mask>'), \n",
    "                                                        append_eos=True).long()\n",
    "    input_ids = input_ids.unsqueeze(0).cuda()\n",
    "    src_lengths = torch.sum(input_ids != 1, dim=1)\n",
    "    return input_ids, src_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pieces = [decode_func(t.unsqueeze(dim=0)) for t in target[:-1]]\n",
    "print(word_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "with torch.no_grad():\n",
    "    for wp in word_pieces:\n",
    "        masked_target = xsum_target[ID].replace(wp, '<mask>', 1)\n",
    "\n",
    "        masked_input, masked_lengths = tokenize_with_mask(masked_target)\n",
    "        masked_outputs = decode_sequence(decode_func,\n",
    "                                         bart_decoder,\n",
    "                                         bart_encoder(masked_input, src_lengths=masked_lengths),\n",
    "                                         tgt_tokens=target.cuda(),\n",
    "                                         verbose=False)\n",
    "        masked_output_ids, masked_tokens, masked_token_probs, token_logits = masked_outputs\n",
    "        assert decode_func(masked_output_ids[0]) == xsum_target[ID]\n",
    "        \n",
    "        loss = -math.log(masked_token_probs[masked_tokens.index(wp)])\n",
    "        print('- {}: {}'.format(wp, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_func(torch.tensor([41552, 43776, 15698]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "src_tokens, src_lengths = tokenize(xsum_source[ID], encode_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ = torch.cat([torch.tensor([0]), target], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([target_[:1], torch.tensor([41552, 43776, 15698])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = bart_encoder(torch.cat([target_[:1], torch.tensor([41552, 43776, 15698])], dim=0).unsqueeze(0).cuda(),\n",
    "                           src_lengths=torch.tensor([4]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([target_[:1], torch.tensor([41552, 43776, 15698])], dim=0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = bart_decoder(torch.tensor([[2, 0]], dtype=torch.long).cuda(), encoder_out, features_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = decoder_outputs[0][:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, t in enumerate(target[:-1]):\n",
    "        start_token, end_token = torch.tensor([0]), torch.tensor([2])\n",
    "        mask_token = torch.tensor([41552, 43776, 15698])\n",
    "\n",
    "        src_tokens = torch.cat([start_token, target[: i], mask_token, end_token], dim=0).unsqueeze(dim=0).cuda()\n",
    "        src_lengths = torch.tensor([src_tokens.shape[1]]).cuda()\n",
    "        prev_output_tokens = torch.cat([torch.tensor([2, 0]), target[: i]], dim=0).unsqueeze(dim=0).cuda()\n",
    "\n",
    "        encoder_out = bart_encoder(src_tokens, src_lengths=src_lengths)\n",
    "        decoder_outputs = bart_decoder(prev_output_tokens, encoder_out, features_only=False)\n",
    "        logits = decoder_outputs[0][:, -1, :]  # [batch_size, vocab]\n",
    "        \n",
    "        probs = softmax(logits)\n",
    "        token, prob = decode_func(t.unsqueeze(dim=0)), probs.squeeze()[t.item()].item()\n",
    "        print('- {}: {}'.format(token, -math.log(prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([    0, 41552, 43776, 15698,     2]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
