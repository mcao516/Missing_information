{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines, get_cmlm_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_bart = BARTModel.from_pretrained('/home/ml/users/cadencao/fairseq/checkpoints/xsum_cmlm_bos',\n",
    "                                           checkpoint_file='checkpoint_best.pt',\n",
    "                                           data_name_or_path='/home/ml/users/cadencao/XSum/fairseq_files/xsum-bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- fine-tuned bart model loaded.\n"
     ]
    }
   ],
   "source": [
    "finetuned_bart.cuda()\n",
    "finetuned_bart.eval()\n",
    "finetuned_bart.half()\n",
    "print('- fine-tuned bart model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/users/cadencao/Downloads/BART_models/bart.large',\n",
    "                                 checkpoint_file='model.pt',\n",
    "                                 data_name_or_path='/home/ml/users/cadencao/Downloads/BART_models/bart.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- bart model loaded.\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "bart.half()\n",
    "print('- bart model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = bart.encode\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- load 11301 samples.\n"
     ]
    }
   ],
   "source": [
    "document_path = '/home/ml/users/cadencao/XSum/fairseq_files/test.source'\n",
    "target_path = '/home/ml/users/cadencao/XSum/fairseq_files/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "\n",
    "assert len(xsum_source) == len(xsum_target)\n",
    "print('- load {} samples.'.format(len(xsum_source)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(source, target, ents):\n",
    "    \"\"\"Get the weight of target sample.\n",
    "    \n",
    "    Args:\n",
    "        source: str\n",
    "        target: str\n",
    "        ents: [{start: 13, end: 23, label: \"ORG\"}, ...]\n",
    "    \n",
    "    Return:\n",
    "        posteriors: list of posterior probilities\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(ents) == 0:\n",
    "        return [1.0]\n",
    "\n",
    "    posteriors = []\n",
    "    for e in ents:\n",
    "        entity = target[e['start']: e['end']]\n",
    "        assert entity in target\n",
    "        masked_hypothesis = '<s> ' + target[0: e['start']] + '###' + target[e['end']:]\n",
    "\n",
    "        masked_input = masked_hypothesis + ' <\\s> ' + source\n",
    "        with torch.no_grad():\n",
    "            posterior = get_cmlm_probability(finetuned_bart,\n",
    "                                             '<s> ' + target,\n",
    "                                             masked_input,\n",
    "                                             (e['start'] + 4, e['end'] + 4),\n",
    "                                             entity, verbose=False)\n",
    "        posteriors.append(posterior)\n",
    "\n",
    "    assert len(posteriors) == len(ents)\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file_path = '/home/ml/users/cadencao/fairseq/preds/xsum_regularized_original_cpb.hypo'\n",
    "\n",
    "xsum_preds = read_lines(prediction_file_path)\n",
    "assert len(xsum_source) == len(xsum_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [14:38,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "posteriors, extracted_ents = [], []\n",
    "\n",
    "for i, (s, p) in tqdm(enumerate(zip(xsum_source[:300], xsum_preds[:300]))):\n",
    "    p = ' '.join(p.split())\n",
    "    ents = nlp(p).to_json()['ents']\n",
    "\n",
    "    extracted_ents.append(ents)\n",
    "    posteriors.append(get_posterior(s, p, ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- average posterior: 0.6350243526848589\n",
      "- percentage of non-factual summary: 0.2866666666666667\n",
      "- percentage of hallucinated entities: 0.13087674714104194\n"
     ]
    }
   ],
   "source": [
    "ent_labels, summary_labels = [], []\n",
    "posterior_sum, counter = 0, 0.\n",
    "\n",
    "for ps in posteriors:\n",
    "    if min(ps) > 0.1:\n",
    "        summary_labels.append(0)\n",
    "    else:\n",
    "        summary_labels.append(1) # non-consistent\n",
    "        \n",
    "    for p in ps:\n",
    "        posterior_sum += p\n",
    "        if p > 0.1:\n",
    "            ent_labels.append(0)\n",
    "        else:\n",
    "            ent_labels.append(1) # hallucinated\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "print('- average posterior: {}'.format(posterior_sum / counter))\n",
    "print('- percentage of non-factual summary: {}'.format(sum(summary_labels) / len(summary_labels)))\n",
    "print('- percentage of hallucinated entities: {}'.format(sum(ent_labels) / len(ent_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - xsum_official (300 samples)\n",
    "# - average posterior: 0.6042669351904417\n",
    "# - percentage of non-factual summary: 0.4\n",
    "# - percentage of hallucinated entities: 0.16062683643486778\n",
    "\n",
    "# - xsum_cedar_min_weighted_last (300 samples)\n",
    "# - average posterior: 0.6248949521352261\n",
    "# - percentage of non-factual summary: 0.32\n",
    "# - percentage of hallucinated entities: 0.14774114774114774\n",
    "\n",
    "# - xsum_cedar_avg_weighted_best (300 samples)\n",
    "# - average posterior: 0.6288346728699337\n",
    "# - percentage of non-factual summary: 0.2966666666666667\n",
    "# - percentage of hallucinated entities: 0.1323529411764706\n",
    "\n",
    "# - cedar_data_drop (300 samples)\n",
    "# - average posterior: 0.6622435274226233\n",
    "# - percentage of non-factual summary: 0.2733333333333333\n",
    "# - percentage of hallucinated entities: 0.13150684931506848\n",
    "\n",
    "# - xsum_regularized_cpb_elr2_cpb.hypo (300 samples)\n",
    "# - average posterior: 0.6239574796195876\n",
    "# - percentage of non-factual summary: 0.28\n",
    "# - percentage of hallucinated entities: 0.13586291309669524\n",
    "\n",
    "# - xsum_regularized_cp1_elr2_cpb (300 samples)\n",
    "# - average posterior: 0.6314182049151594\n",
    "# - percentage of non-factual summary: 0.29333333333333333\n",
    "# - percentage of hallucinated entities: 0.13506815365551425\n",
    "\n",
    "# - xsum_regularized_cpb_elr10_cp5 (300 samples)\n",
    "# - average posterior: 0.6293614379030468\n",
    "# - percentage of non-factual summary: 0.27\n",
    "# - percentage of hallucinated entities: 0.13451776649746192\n",
    "\n",
    "# - xsum_regularized_cpb_elr10_cp11 (300 samples)\n",
    "# - average posterior: 0.6293614379030468\n",
    "# - percentage of non-factual summary: 0.27\n",
    "# - percentage of hallucinated entities: 0.13451776649746192\n",
    "\n",
    "# - xsum_regularized_cpb_elr30_cp9\n",
    "# - average posterior: 0.6387096765756954\n",
    "# - percentage of non-factual summary: 0.2733333333333333\n",
    "# - percentage of hallucinated entities: 0.13127413127413126\n",
    "\n",
    "# -xsum_regularized_original_cpb\n",
    "# - average posterior: 0.6350243526848589\n",
    "# - percentage of non-factual summary: 0.2866666666666667\n",
    "# - percentage of hallucinated entities: 0.13087674714104194\n",
    "\n",
    "# - xsum_clean_cp1 (300 samples)\n",
    "# - average posterior: 0.6434800207703358\n",
    "# - percentage of non-factual summary: 0.32666666666666666\n",
    "# - percentage of hallucinated entities: 0.14478527607361963\n",
    "\n",
    "# - xsum target (300 samples)\n",
    "# - average posterior: 0.5156889161579035\n",
    "# - percentage of non-factual summary: 0.55\n",
    "# - percentage of hallucinated entities: 0.2813953488372093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average posterior prob:\n",
    "\n",
    "# reference: 0.5103260373198956\n",
    "# data-dropout: 0.6402941753973592\n",
    "# xsum_official: 0.6002646216892829\n",
    "# xsum self-trained on Cedar: 0.5992162492884309\n",
    "\n",
    "# xsum_binary_smoothly_weighted (200): 0.6287983280432797\n",
    "# xsum_cedar_min_weighted_best (200): 0.6249476049270435\n",
    "# xsum_cedar_min_weighted_last (200): 0.6207262391602929\n",
    "# xsum_binary_weighted (200): 0.6580150275871669\n",
    "\n",
    "# xsum cedar checkpoint1 (100): 0.6132371826385169\n",
    "# xsum cedar checkpoint2 (100): 0.61654346501808\n",
    "# xsum cedar checkpoint3 (100): 0.6229014194340766\n",
    "\n",
    "# xsum cedar checkpoint1 (500): 0.5925646644582644\n",
    "# xsum cedar checkpoint2 (500): 0.60001381397845\n",
    "# xsum cedar checkpoint3 (500): 0.603983573738802\n",
    "\n",
    "# xsum cedar checkpoint1 (1000): 0.6070493213913469\n",
    "# xsum cedar checkpoint2 (1000): 0.6027837024769428\n",
    "# xsum cedar checkpoint3 (1000): 0.6016024746051729"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
