{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/bart.large.xsum',\n",
    "                                 checkpoint_file='model.pt',\n",
    "                                 data_name_or_path='/home/ml/cadencao/Downloads/BART_models/bart.large.xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- activate evaluation mode\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "bart.half()\n",
    "print('- activate evaluation mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = lambda x: bart.task.source_dictionary.encode_line(bart.bpe.encode(x) + ' </s>', append_eos=False).long()\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fairseq.models.bart.model.BARTModel'>\n",
      "<class 'fairseq.models.transformer.TransformerEncoder'>\n",
      "<class 'fairseq.models.transformer.TransformerDecoder'>\n"
     ]
    }
   ],
   "source": [
    "bart_encoder = bart.model.encoder\n",
    "bart_decoder = bart.model.decoder\n",
    "print(type(bart.model))\n",
    "print(type(bart_encoder))\n",
    "print(type(bart_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (sentence, span)\n",
    "# output: [1, 1, 1, 0, 0, 0, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister . He once participated in a takeover of the Iranian Consulate in San Francisco . The Iranian foreign minister tweets in English .\n"
     ]
    }
   ],
   "source": [
    "SENTENCE = \"Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister . He once participated in a takeover of the Iranian Consulate in San Francisco . The Iranian foreign minister tweets in English .\"\n",
    "print(SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29880, 41007, 24942,   625, 17122,  1594,    34,  1240,    55,    86,\n",
       "           19,   610,  9153,    87,   143,    97,  1093,  1269,   479,    91,\n",
       "          683,  7849,    11,    10, 10260,     9,     5,  5051,  9051, 10246,\n",
       "           11,   764,  2659,   479,    20,  5051,  1093,  1269,  6245,    11,\n",
       "         2370,   479,     2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_func(SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moh', 'ammad', ' Jav', 'ad', ' Zar', 'if', ' has', ' spent', ' more', ' time', ' with', ' John', ' Kerry', ' than', ' any', ' other', ' foreign', ' minister', ' .', ' He', ' once', ' participated', ' in', ' a', ' takeover', ' of', ' the', ' Iranian', ' Cons', 'ulate', ' in', ' San', ' Francisco', ' .', ' The', ' Iranian', ' foreign', ' minister', ' tweets', ' in', ' English', ' .', '']\n"
     ]
    }
   ],
   "source": [
    "print([decode_func(torch.tensor([i])) for i in encode_func(SENTENCE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(target, tokens):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        target: 'Justin Martin'\n",
    "        tokens: ['The', ' Archbishop', ' of', ...]\n",
    "    \"\"\"\n",
    "    all_indices = []\n",
    "    for i, t in enumerate(tokens):\n",
    "        t = t.strip()\n",
    "        indices = []\n",
    "        if t in target:\n",
    "            indices.append(i)\n",
    "            if t == target:\n",
    "                all_indices.extend(indices)\n",
    "                continue\n",
    "            elif i + 1 < len(tokens):\n",
    "                for ni, rt in enumerate(tokens[i + 1:]):\n",
    "                    t += rt\n",
    "                    indices.append(i + ni + 1)\n",
    "                    if t == target:\n",
    "                        all_indices.extend(indices)\n",
    "                        break\n",
    "                    elif t not in target:\n",
    "                        break\n",
    "    return all_indices\n",
    "\n",
    "def build_mask(target, tokens):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        target: 'Justin Martin'\n",
    "        tokens: ['The', ' Archbishop', ' of', ...]\n",
    "    \"\"\"\n",
    "    indices = get_indices(target, tokens)\n",
    "    mask = torch.ones(len(tokens), dtype=torch.long)\n",
    "    for i in indices:\n",
    "        mask[i] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = 'The League One match between Oldham and Blackpool has been postponed because of a waterlogged pitch.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', ' League', ' One', ' match', ' between', ' Old', 'ham', ' and', ' Black', 'pool', ' has', ' been', ' postponed', ' because', ' of', ' a', ' water', 'log', 'ged', ' pitch', '.', '']\n"
     ]
    }
   ],
   "source": [
    "print([decode_func(torch.tensor([i])) for i in encode_func(SENTENCE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_mask(\"Oldham\", [decode_func(torch.tensor([i])) for i in encode_func(SENTENCE)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = '/home/ml/cadencao/XSum/fairseq_files/test.target'\n",
    "xsum_target = read_lines(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11301/11301 [00:32<00:00, 351.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for tgt in tqdm(xsum_target):\n",
    "    # sample a span\n",
    "    tokens = tgt.split()\n",
    "    bos_index = randint(0, len(tokens) - 1)\n",
    "    eos_index = randint(bos_index, len(tokens) - 1)\n",
    "    span = ' '.join(tokens[bos_index: eos_index + 1])\n",
    "    \n",
    "    ids = encode_func(tgt)\n",
    "    word_piece = [decode_func(torch.tensor([i])) for i in ids]\n",
    "    indices = get_indices(span, word_piece)\n",
    "\n",
    "    if len(indices) == 0:\n",
    "#         print(\"- target: {}\".format(tgt))\n",
    "#         print(\"- span: {}\".format(span))\n",
    "        continue\n",
    "\n",
    "    continued = [indices[0]]\n",
    "    if len(indices) > 1:\n",
    "        for i in indices[1:]:\n",
    "            if i - continued[-1] == 1:\n",
    "                continued.append(i)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    extracted = ''.join(word_piece[continued[0]: continued[-1] + 1]).strip()\n",
    "    assert extracted == span, \"- tgt: {}; span: {}; extracted: {}\".format(tgt, span, extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203575\n"
     ]
    }
   ],
   "source": [
    "train_target_path = '/home/ml/cadencao/XSum/fairseq_files/train.target'\n",
    "train_source_path = '/home/ml/cadencao/XSum/fairseq_files/train.source'\n",
    "xsum_train_target = read_lines(train_target_path)\n",
    "xsum_train_source = read_lines(train_source_path)\n",
    "print(len(xsum_train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203575it [51:22, 66.04it/s]\n"
     ]
    }
   ],
   "source": [
    "target_masks = []\n",
    "\n",
    "for s, t in tqdm(zip(xsum_train_source, xsum_train_target)):\n",
    "    tokens = [decode_func(torch.tensor([i])) for i in encode_func(t)]\n",
    "    mask = torch.ones(len(tokens), dtype=torch.long)\n",
    "    \n",
    "    # NER\n",
    "    t_ents = [e.text for e in nlp(t).ents]\n",
    "    for e in t_ents:\n",
    "        for ep in e.split():\n",
    "            if ep not in s:\n",
    "                tmp_mask = build_mask(ep, tokens)\n",
    "                mask.masked_fill_((1 - tmp_mask).bool(), 0)\n",
    "   \n",
    "    # add processed\n",
    "    target_masks.append(mask)\n",
    "#     print(tokens)\n",
    "#     print(mask)\n",
    "    \n",
    "#     if len(target_mask) == 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.mask', 'w') as file:\n",
    "    for t in target_masks:\n",
    "        for i in t.tolist():\n",
    "            file.write('{} '.format(i))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "with open('train.mask', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        value = [int(i) for i in line.split()]\n",
    "        masks.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
